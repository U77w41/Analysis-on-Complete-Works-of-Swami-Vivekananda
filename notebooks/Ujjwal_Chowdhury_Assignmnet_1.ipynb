{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Ujjwal Chowdhury\n",
    "## Assignment 1\n",
    "## Reg. No.: B2130051\n",
    "## MSc BDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XGI6zJZDuCy"
   },
   "source": [
    "# Reading\n",
    "Download the file and Read it using pickle as given below.\n",
    "\n",
    "It is a python dict: \n",
    "    \n",
    "    'text' is str object consists of all the sentences from all the volumes  \n",
    "    'count' is the exact distict words present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # For reading the dataset\n",
    "from pathlib import Path #  For getting the directory path\n",
    "import json # For saving the list of words and tokens\n",
    "PATH = str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YcHT-dOvDBAU",
    "outputId": "ddd0ab45-6416-42db-fff0-b7d93dfdba00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['text', 'count']), 27301)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(PATH + \"/data/processed/dataset.pkl\", 'rb') as f:\n",
    "    dataset = pickle.load(f) \n",
    "dataset.keys(), dataset['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('.',' ')\n",
    "df['text'] = df['text'].str.replace(',',' ')\n",
    "df['text'] = df['text'].str.replace('?',' ')\n",
    "df['text'] = df['text'].str.replace('!',' ')\n",
    "df['text'] = df['text'].str.replace(';',' ')\n",
    "df['text'] = df['text'].str.replace(':',' ')\n",
    "df['text'] = df['text'].str.replace('“',' ')\n",
    "df['text'] = df['text'].str.replace('“',' ')\n",
    "df['text'] = df['text'].str.replace('”',' ')\n",
    "df['text'] = df['text'].str.replace('-','')\n",
    "df['text'] = df['text'].str.replace('—','')\n",
    "df['text'] = df['text'].str.replace(\"’\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Response To Welcome At the Worlds Parliament of Religions  Chicago 11th September  1893 Sisters and Brothers of America  It fills my heart with joy unspeakable to rise in response to the warm and cordial welcome which you have given us  I thank you in the name of the most ancient order of monks in the world  I thank you in the name of the mother of religions  and I thank you in the name of millions and millions of Hindu people of all classes and sects  My thanks  also  to some of the speakers o\n"
     ]
    }
   ],
   "source": [
    "# Lets print a portion of the text\n",
    "print(str[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the list of words by tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1486756"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identifiers = {}\n",
    "idx = 0\n",
    "for word in str.split():\n",
    "    if word not in identifiers:\n",
    "        identifiers[word] = idx\n",
    "        idx += 1\n",
    "\n",
    "list_values = [identifiers[word] for word in str.split()]\n",
    "\n",
    "len(list_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Savings the list of tokens as a simple text file\n",
    "with open(PATH + '/data/processed/list.txt', 'w') as f:\n",
    "    f.write(json.dumps(list_values))\n",
    "\n",
    "# Now read the file back into a Python list object\n",
    "with open(PATH + '/data/processed/list.txt', 'r') as f:\n",
    "    data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash functions are defined as (a*x+b) %c, where x is an element of the set.\n",
      "Enter the number of hash functions: 2\n",
      "Enter the space-separated values of a, b and c: 12345 98765 1234567\n",
      "Enter the space-separated values of a, b and c: 123 653 1234567\n",
      "Counts recorded for each hash:  [131072, 16384]\n",
      "Approximate number of elements from mean-median approximation:  36864\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Hash functions are defined as (a*x+b) %c, where x is an element of the set.\")\n",
    "inputCount = int(input(\"Enter the number of hash functions: \"))\n",
    "abcList = []\n",
    "\n",
    "for i in range(inputCount):\n",
    "    inputList = input(\"Enter the space-separated values of a, b and c: \").split(\" \")\n",
    "    abcList.append([int(i) for i in inputList])\n",
    "finalCountsRecorded = []\n",
    "\n",
    "for i in abcList:\n",
    "    binElems = []\n",
    "    for j in set(data):             #Evaluates the hash function, then converts it to binary. \n",
    "        binElems.append(str(bin((i[0]*j+i[1])%i[2])).split(\"b\")[1])  #Appends binary output to a list\n",
    "    greatestTrailing = 0             \n",
    "    for k in binElems:             #Processes every element for that specific hash\n",
    "        reversedCount = k[::-1]    \n",
    "        count = 0\n",
    "        for i in reversedCount:\n",
    "            if(i=='1'):\n",
    "                if(count>greatestTrailing):\n",
    "                    greatestTrailing = count       #The greatest number of trailing zeros are established\n",
    "                break\n",
    "            else:\n",
    "                count+=1\n",
    "    finalCountsRecorded.append(2**greatestTrailing)      #The formula R = 2^r is applied, where R is number of elems,\n",
    "                  #and r is max trailing zeros recorded\n",
    "print(\"Counts recorded for each hash: \",finalCountsRecorded)\n",
    "divider = inputCount//2\n",
    "set1 = finalCountsRecorded[:divider]\n",
    "set2 = finalCountsRecorded[divider:]\n",
    "means = [sum(set1)/inputCount,sum(set2)/inputCount]      #Note: For demonstration purposes, we only have two sets here.\n",
    "median = sum(means)/2             #    Thus, median is defined as (sum of means)/2 \n",
    "\n",
    "print(\"Approximate number of elements from mean-median approximation: \",int(median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words in the dataset is: 36077\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique words in the dataset is:', len(set(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate unique words by FM Algorithm 36864\n",
    "\n",
    "Number of actual unique words in the dataset is: 36077"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "K0teX50LFyji"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
